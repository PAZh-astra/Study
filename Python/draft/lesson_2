//1__________________________________________________________________________________________________________________
from sklearn.datasets import load_iris
iris = load_iris ()

#_узнать все состовляющие набора данных iris (вызов load_iris из библиотеки)
#print(iris.keys())
#print(iris)
#print (iris["DESCR"])
import matplotlib.pyplot as plt
#_значения таблицы
#print(iris.data)
#_сортировка таблицы по отдельным критериям
#print(iris.data.T)

#_features - переменная для хранения "list" (любая)
featurse = iris.data.T

#_вызов функции по первой характеристики (начиная с нуль)
#print(featurse[0]) 
#_присвоим эту функцию к отдельному имени (любая)
sepal_length = featurse [0]
sepal_width = featurse [1]
petal_length = featurse [2]
petal_width = featurse [3]

#_узнать еденицу измерения
#print(iris.feature_names)
sepal_length_label = iris.feature_names [0]
sepal_width_label = iris.feature_names [1]
petal_length_label = iris.feature_names [2]
petal_width_label = iris.feature_names [3]

#_создадим диаграмму рассеивания через plt (функция scatter), target - протсо переменная 
plt.scatter(sepal_lengh, sepal_width, c=iris.target)
plt.xlabel (sepal_length_label)
plt.ylabel (sepal_width_label)
#_показать результат
plt.show()

plt.scatter(petal_length, petal_width, c=iris.target)
plt.xlabel (petal_length_label)
plt.ylabel (petal_width_label)
plt.show()

//2__________________________________________________________________________________________________________________
from sklearn.datasets import load_iris
#_функция, которой предост-ся часть средств масштаб-ия, что позволит заупстить классификатор ближайших соседей
from sklearn.neighbors import KNeighborsClassifier
#_импортируем функцию разделения (рандомную)
from sklearn.model_selection import train_test_split 

import numpy as np
iris = load_iris ()

#_split - есть данные (данные X, которые запускаются в данную модель, и цель Y, которую пытаемся предсказать)
#_X_test и Y_test - данные, которые мы скроем для последующей проверки
#_random равен нулю для получения тех же компонентов из конкретного набора данных этих переменных
X_train, X_test, Y_train, Y_test = train_test_split(iris['data'], iris['target'], random_state=0)

#_knn-переменная; уст-м классификатор ближайших сосоеде, который будет диктовать сколько "соседей" рассматривать для данной модели (выбрали 1 соседа)
knn = KNeighborsClassifier(n_neighbors=1)
#_подгонка в отношении некоторых данных
knn.fit(X_train, Y_train)

#_образец данных для проверки
X_new = np.array([[5.0, 2.9, 1.0, 0.2]])

#_shape - размеры массива, его форма
#print (X_new.shape)

#_опрееделим переменную (используя подгонку) для спрогнозирования результатат данной выборки
#prediction = knn.predict(X_new)
#print(prediction)

#_составить прогноз и соспоставить со скрытым екстом Y, определив правильная ли модель или нет
print(knn.score(X_test, Y_test))
#_модель сможет предсказть с точностью в 97%


//3__________________________________________________________________________________________________________________
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from sklearn import datasets
from sklearn.decomposition import PCA

# импортировать данные для программы
iris = datasets.load_iris()
X = iris.data[:, :2]  # we only take the first two features.
y = iris.target

x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5
y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5

plt.figure(2, figsize=(8, 6))
plt.clf()

# Построение тренировочных точек
plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Set1,
            edgecolor='k')
plt.xlabel('Sepal length')
plt.ylabel('Sepal width')

plt.xlim(x_min, x_max)
plt.ylim(y_min, y_max)
plt.xticks(())
plt.yticks(())

# Чтобы лучше понять взаимодействие размеров построить первые три измерения PCA
fig = plt.figure(1, figsize=(8, 6))
ax = Axes3D(fig, elev=-150, azim=110)
X_reduced = PCA(n_components=3).fit_transform(iris.data)
ax.scatter(X_reduced[:, 0], X_reduced[:, 1], X_reduced[:, 2], c=y,
           cmap=plt.cm.Set1, edgecolor='k', s=40)
ax.set_title("First three PCA directions")
ax.set_xlabel("1st eigenvector")
ax.w_xaxis.set_ticklabels([])
ax.set_ylabel("2nd eigenvector")
ax.w_yaxis.set_ticklabels([])
ax.set_zlabel("3rd eigenvector")
ax.w_zaxis.set_ticklabels([])

plt.show()
